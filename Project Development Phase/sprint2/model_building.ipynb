{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**import keras libraries**"
      ],
      "metadata": {
        "id": "vgRSkMuZBXMY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRqCbicJBVlU"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing ImageDataGenerator from Keras**"
      ],
      "metadata": {
        "id": "yUmEZuZhCA0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "PSGR_yqNCCeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Parameters**"
      ],
      "metadata": {
        "id": "iQBw-LqnCG6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "SXnfLoxLCLJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying ImageDataGenerator functionality to train dataset**"
      ],
      "metadata": {
        "id": "J8fEYfR7CY70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uCXaFS-EFSH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b915bcd0-af07-4500-b915-725a0dfcc88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/drive/dataset/Dataset/Dataset/train_set',target_size=(128,128),batch_size=32,class_mode='binary')\n"
      ],
      "metadata": {
        "id": "q3-efMT-CzXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b915e5-e4fc-4686-9fdd-ecb35ef3ebfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 436 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying ImageDataGenerator functionality to test dataset**"
      ],
      "metadata": {
        "id": "6fbOM-zPC4Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/drive/dataset/Dataset/Dataset/test_set',target_size=(128,128),batch_size=32,class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKuc-sXS44Yu",
        "outputId": "fb5b95c7-289e-452b-cbf4-ad8bdc96b144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Model Building Libraries**"
      ],
      "metadata": {
        "id": "GpFdlJwQ8Rva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to define the linear Initialisation import sequential\n",
        "from keras.models import Sequential\n",
        "#to add layers import Dense\n",
        "from keras.layers import Dense\n",
        "#to create Convolutional kernel import convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer \n",
        "from keras.layers import MaxPooling2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "CL4-NERL8bAr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the model**"
      ],
      "metadata": {
        "id": "VJvYJaYr8mHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "1XcijE_I8qW7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding CNN Layers**"
      ],
      "metadata": {
        "id": "CwcdJO3E80mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
        "#add maxpooling layers\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add faltten layer\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "hf1pq64W85UI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add Dense layers**"
      ],
      "metadata": {
        "id": "UqMvXTMa9CJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layers\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "XNw8EO309GQP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**configuring the learning process**"
      ],
      "metadata": {
        "id": "WwPCVpH59RDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5Cg8JR7-9QoP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "23BCuPeV-GAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLUJGqM1-Jv9",
        "outputId": "691f3265-ca45-4228-9584-eea133f76c7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 140s 10s/step - loss: 2.4805 - accuracy: 0.6307 - val_loss: 0.9644 - val_accuracy: 0.6942\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 32s 2s/step - loss: 0.5925 - accuracy: 0.7867 - val_loss: 0.1540 - val_accuracy: 0.9256\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.2832 - accuracy: 0.8578 - val_loss: 0.0988 - val_accuracy: 0.9669\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.2280 - accuracy: 0.8922 - val_loss: 0.0923 - val_accuracy: 0.9669\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.2053 - accuracy: 0.9060 - val_loss: 0.0847 - val_accuracy: 0.9587\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.2059 - accuracy: 0.9128 - val_loss: 0.0771 - val_accuracy: 0.9752\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 28s 2s/step - loss: 0.1643 - accuracy: 0.9450 - val_loss: 0.0727 - val_accuracy: 0.9752\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 29s 2s/step - loss: 0.1560 - accuracy: 0.9266 - val_loss: 0.0857 - val_accuracy: 0.9752\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1683 - accuracy: 0.9289 - val_loss: 0.0980 - val_accuracy: 0.9752\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 28s 2s/step - loss: 0.1716 - accuracy: 0.9266 - val_loss: 0.0932 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00be91aad0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model**"
      ],
      "metadata": {
        "id": "uz1PSSOp-7lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"forest.h5\")"
      ],
      "metadata": {
        "id": "Voo6hamh_Cpm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictions**"
      ],
      "metadata": {
        "id": "tIRa6fwc_JFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import load model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image from keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "#import cv2\n",
        "import cv2\n",
        "#load the saved model\n",
        "model=load_model('forest.h5')\n",
        "img=image.load_img('/content/drive/MyDrive/drive/dataset/Dataset/Dataset/test_set/forest/0.48007200_1530881924_final_forest.jpg')\n",
        "x=image.img_to_array(img)\n",
        "res=cv2.resize(x,dsize=(128,128),interpolation=cv2.INTER_CUBIC)\n",
        "#expand the image shape\n",
        "x=np.expand_dims(res,axis=0)"
      ],
      "metadata": {
        "id": "u0Tsagi2_Oee"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FPiaKlg_yAR",
        "outputId": "8e576c77-06b5-4e73-c571-99ef6122156b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 355ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBq5JQTM_1Vs",
        "outputId": "e638edf0-8992-4cc4-d9d9-8ef526ae2668"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.2659456e-21]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}